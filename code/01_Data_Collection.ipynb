{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents:\n",
    "-  [Digital Nomad Data Collection](#Digital-Nomad-Data-Collection)\n",
    "-  [Solo Travel Data Collection](#Solo-Travel-Data-Collection)\n",
    "-  [Save as JSON](#Save-as-JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psaw in /Users/connie/anaconda3/lib/python3.6/site-packages (0.0.7)\n",
      "Requirement already satisfied: requests in /Users/connie/anaconda3/lib/python3.6/site-packages (from psaw) (2.18.4)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/connie/anaconda3/lib/python3.6/site-packages (from requests->psaw) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /Users/connie/anaconda3/lib/python3.6/site-packages (from requests->psaw) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /Users/connie/anaconda3/lib/python3.6/site-packages (from requests->psaw) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/connie/anaconda3/lib/python3.6/site-packages (from requests->psaw) (2018.4.16)\n"
     ]
    }
   ],
   "source": [
    "!pip install psaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psaw import PushshiftAPI\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate PushshiftAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = PushshiftAPI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digital Nomad Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We collect posts from our first subreddit: r/digitalnomad. \n",
    "-  In order to retrieve the most recent posts, we specify January 1, 2018 for `after`. Only posts after this date will be collected.\n",
    "-  We only want the `title`, `selftext` and `url` for each post. All other information will not be collected.\n",
    "-  To avoid class imbalance, we only want to collect a maximum of 6,000 posts since the specified date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dn_posts = list(api.search_submissions(after=int(dt.datetime(2018, 1, 1).timestamp()),\n",
    "                                       subreddit='digitalnomad',\n",
    "                                       filter=['title', 'selftext', 'url'],\n",
    "                                       limit=6000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a total of 5,705 posts from January 1, 2018 to December 19, 2018."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solo Travel Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We collect posts from our second subreddit: r/solotravel.\n",
    "-  We specify August 10, 2018 for `after` because we want the most recent posts. r/solotravel is much more active than r/digitalnomad, and as a result, has more posts in a shorter time frame.\n",
    "-  Again, we only want `title`, `selftext` and `url` for each post. All other information will not be collected.\n",
    "-  Knowing that r/solotravel has more posts, we set a maximum of 6,000 posts to undersample our majority class and prevent class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_posts = list(api.search_submissions(after=int(dt.datetime(2018, 8, 10).timestamp()), \n",
    "                                       subreddit='solotravel', \n",
    "                                       filter=['title', 'selftext', 'url'], \n",
    "                                       limit=6000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(st_posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We collected 6,000 posts from August 10, 2018 to December 19, 2018. Given that we have exactly 6,000 posts, there appears to be more posts available if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save as JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before saving the data as json files, we want to note when the data was collected. Since both subreddits are continuously being updated, including the time will help us determine how up to date the data is and how prevalent our findings are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../data/dn_posts_{now:.0f}.json', 'w+') as f:\n",
    "    json.dump(dn_posts, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../data/st_posts_{now:.0f}.json', 'w+') as f:\n",
    "    json.dump(st_posts, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
